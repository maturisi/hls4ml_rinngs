{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RiNNgs dense model \n",
    "This notebook is dedicated to design, develop and test solution for online ring counting at NA62-RICH.\n",
    "\n",
    "The notebook is derived from [hls-tutorial](https://github.com/fastmachinelearning/hls4ml-tutorial).\n",
    "\n",
    "1. General\n",
    "    1. Load dependancies\n",
    "    2. Define global constants\n",
    "2. Data \n",
    "    1. Shuffle dataset\n",
    "    2. Separate features and targets\n",
    "3. Model \n",
    "    1. Create the model\n",
    "    2. Configure the model and start training\n",
    "4. Model in HLS \n",
    "\n",
    "5. HLS Synthesis\n",
    "6. Synthesis\n",
    "\n",
    "## 1 Definitions and dependancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed)\n",
    "print (\"TensorFlow version: \" + tf.__version__)\n",
    "\n",
    "import os\n",
    "os.environ['PATH'] = '/opt/Xilinx/Vivado/2020.1/bin:' + os.environ['PATH']\n",
    "\n",
    "\n",
    "import plotting\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We define global constants, custom datatypes and functions to handle RICH data and rings information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from include.helper_fun import * \n",
    "#from include.helper_values_rings import *\n",
    "N_HITS_MAX=64\n",
    "N_PMT = 2048\n",
    "maxpmt = 2048\n",
    "maxhits_evt = 128\n",
    "maxrings_evt = 8     #the same as in kernel_histogram.cu\n",
    "r_pmt = 9.0\n",
    "samples=80000 #samples for each class #we are assuming that there is the same amount of samples for each class \n",
    "nLabel=4 #4 features (rings 0 1 2 2+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Data processing\n",
    "We define a function to import data and a class for fitted ring data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataring:\n",
    "    def __init__(self, x=0.,y=0.,r=0., tothits=0):\n",
    "        self.x=x\n",
    "        self.y=y\n",
    "        self.r=r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function to parse datafile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_formatNN(listfiles, all_hits_list, all_features_list, all_datarings, samples):\n",
    "    #import numpy as np\n",
    "    debughits=0 #only to debug, it prints the hits for each event\n",
    "    hits_array=np.zeros(N_HITS_MAX)\n",
    "    count_events=0\n",
    "    readringdata=[]\n",
    "    test_PMT=[]\n",
    "    for idx, file_ in enumerate(listfiles):\n",
    "        with open(file_) as loadfile:\n",
    "            print(\"Opening %s\" % file_)\n",
    "            for indline,line in enumerate(loadfile):\n",
    "                if line.split()[0].startswith('0x'):\n",
    "                    nrings=line.split()[1]\n",
    "                    nhits=line.split()[3]\n",
    "                    if int(nhits)>N_HITS_MAX:\n",
    "                        nhits=N_HITS_MAX\n",
    "                    for nh in range(int(nhits)):\n",
    "                        npmt=int(line.split()[4+(3*nh)])\n",
    "                        hits_array[nh]=npmt\n",
    "                        if (debughits):\n",
    "                            test_PMT.append(int(npmt))\n",
    "                        if nh==int(nhits)-1:\n",
    "                            all_hits_list.append(hits_array)\n",
    "                            all_features_list.append(idx) #NOTE: data files must be ordered according to features in filelist\n",
    "                            hits_array=np.zeros(N_HITS_MAX)\n",
    "                            if (debughits):\n",
    "                                test_PMT.sort() #sort degli hit per comodit√† di confronto\n",
    "                                print(test_PMT)\n",
    "                                test_PMT=[]\n",
    "                    readringdata.append(int(nhits))\n",
    "                    readringdata.append(int(nrings))\n",
    "                    storedataring=Dataring()\n",
    "                    if int(nrings) != 0:\n",
    "                        for nr in range(int(nrings)):\n",
    "                            ringline=next(loadfile, '').split()\n",
    "                            storedataring.x=float(ringline[2])\n",
    "                            storedataring.y=float(ringline[3])\n",
    "                            storedataring.r=float(ringline[4])\n",
    "                            readringdata.append( storedataring )\n",
    "                            storedataring=Dataring()\n",
    "                    elif int(nrings)==0:\n",
    "                        readringdata.append( storedataring )\n",
    "                    all_datarings.append(readringdata)\n",
    "                    readringdata=[] #initialize\n",
    "                    count_events+=1\n",
    "                    if count_events==samples:\n",
    "                        count_events=0\n",
    "                        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch the GPURICH 2017 dataset \n",
    "If you've just cloned the repo rember to untar -xvf the compressed archive (tar.gz) before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# python arrays to house RICH and rings data\n",
    "data=[]   # hit list, each element is an event\n",
    "target=[] # label list, eache element is a prediction for an event\n",
    "rings=[] # ring data, each elements [ nhits, nrings, Datarings1, Datarings2, ...  ]\n",
    "print(\"##RECO_NN FORMAT\")     \n",
    "folder= \"data/GPURICH_2017_dataset_1/\"\n",
    "file=['merged_0rings_100000events.log', 'merged_1rings_100000events.log', 'merged_2rings_100000events.log', 'merged_3rings_83498events.log']     \n",
    "file=[folder+x for x in file]     \n",
    "read_data_formatNN(file, data, target, rings, samples) \n",
    "\n",
    "\n",
    "# check we have read enough data-samples\n",
    "samples_available=int(len(data)/nLabel)  #how many samples we have available for each class\n",
    "if samples_available<samples: \n",
    "    print(\"WARNING: samples_available %d instead of the default %d\" % (samples_available, samples))\n",
    "    samples=samples_available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's print some information about the data set\n",
    "A global overview on dataset composition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total labels %d\" % nLabel)\n",
    "print(\"Total events per label %d\" % samples)\n",
    "\n",
    "print(len(data))\n",
    "print(len(target))\n",
    "print(len(rings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "a = le.fit(target)\n",
    "b = le.classes_\n",
    "print(b[:4])\n",
    "\n",
    "\n",
    "# define an array of literal string for ROC curves used by hls4ml plotting module\n",
    "labels = np.array(['zero', 'one', 'two', 'three+'])\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data of a particular event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eventID = 3*80000+4\n",
    "print(\"Event[#]: %d\" % eventID)\n",
    "print(\"Label[#rings]: %d \" % target[eventID])\n",
    "print(\"HitList:\")\n",
    "print(data[eventID])\n",
    "print(rings[eventID])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and test fractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to be checked, uneused?\n",
    "#train_fraction=0.8\n",
    "#trainSize=int(samples*train_fraction)\n",
    "#testSize=int(samples*(1-train_fraction))\n",
    "#print(\"For each feature we use %d events as training samples and %d for testing\" % (trainSize, testSize))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy array\n",
    "We use numpy package for easy data manipulation. \n",
    "Note that we keep a copy of the arrays as they were, before any manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "npEvent=np.array(data) \n",
    "npTarget=np.array(target) \n",
    "npEvent_sum=np.sum(npEvent,axis=1) \n",
    "npEvent_orig=np.copy(npEvent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling\n",
    "Data are normalized. Using N_PMT as scale factor the data range is from 0 to 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npEvent=(npEvent/N_PMT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is added with the extra column 'evID' to allow target determination after shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.copy(npEvent)\n",
    "X=np.insert(X, 0, [val for val in range(samples*nLabel)], axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is split in two random subsets, train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_ind, X_valid_ind, y_train, y_valid = train_test_split(X,\n",
    "                                                              to_categorical(npTarget, nLabel),\n",
    "                                                              test_size=0.2,\n",
    "                                                              random_state=0)\n",
    "\n",
    "#APE     #X_train_ind, X_valid_ind, y_train, y_valid = train_test_split(X,\n",
    "#HLS4ML  #X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "#SKLEARN #X_train,     X_test, y_train,     y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "# the suffix 'ind is to indicate this is the data with the extra evID column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the data for future re-use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('X_train_ind.npy', X_train_ind)\n",
    "np.save('X_valid_ind.npy', X_valid_ind)\n",
    "np.save('y_train.npy', y_train)\n",
    "np.save('y_valid.npy', y_valid)\n",
    "np.save('classes.npy', le.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The extra column is removed for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train_ind[:,1:] \n",
    "X_valid=X_valid_ind[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrap data in Dataset objects - Required (not yet enforced) by TensorFlow2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow as tf \n",
    "train_data = tf.data.Dataset.from_tensor_slices((X_train, y_train)) \n",
    "val_data = tf.data.Dataset.from_tensor_slices((X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The batch size must now be set on the Dataset objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=1024\n",
    "train_data = train_data.batch(batch_size) \n",
    "val_data = val_data.batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disable AutoShard \n",
    "Note: shard is deterministic. \n",
    "The Dataset produced by A.shard(n, i) will contain all elements of A whose index mod n = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = tf.data.Options() \n",
    "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.OFF \n",
    "train_data = train_data.with_options(options) \n",
    "val_data = val_data.with_options(options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we give a weight to the categories for training.\n",
    "to \"pay more attention\" to samples from an under-represented class. \n",
    "NOTE: class 1 has low accurancy result, it is not under-represented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = {0: 1,\n",
    "                1: 1.25, #weight bigger for the class with less samples\n",
    "                2: 1,\n",
    "                3: 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model in Keras\n",
    "We use 2 hidden layers with 64, then 16 neurons.\n",
    "Each layer will use relu activation. \n",
    "Add an output layer with 4 neurons (one for each class)\n",
    "then finish with Softmax activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Activation, Dense, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from callbacks import all_callbacks # local custom python module by hls4ml team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set the input shape\n",
    "input_shape = (N_HITS_MAX,)\n",
    "print(f'Feature shape: {input_shape}')\n",
    "\n",
    "inputs  = tf.keras.Input(shape=input_shape,name = 'input')\n",
    "h1      = Dense(64, activation='elu',name='fc1')(inputs)\n",
    "h2      = Dense(16, activation='relu',name='fc2') (h1)\n",
    "#model.add(BatchNormalization())\n",
    "outputs = Dense( 4, activation='softmax',name='output')(h2)\n",
    "model   = Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model \n",
    "Train the model (try to fuse hls4ml and ape trainings code, with no big success for now)\n",
    "and save the json and h5 file to skip the training in future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN=True\n",
    "VERBOSE=True\n",
    "nepochs= 1000\n",
    "\n",
    "if TRAIN:\n",
    "    adam = Adam(lr=0.0001)\n",
    "    model.compile(optimizer=adam, loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
    "    \n",
    "    # instance of the class 'all_callbacks' for custom callback functions (from hls4ml)\n",
    "    # from tutorial part1 The callbacks will decay the learning rate and save the model into a directory 'model_1' \n",
    "    #The model isn't very complex, so this should just take a few minutes even on the CPU. \n",
    "    #If you've restarted the notebook kernel after training once, set train = False to load the trained model.\n",
    "\n",
    "    #folder='model_1'\n",
    "    # callbacks = all_callbacks(stop_patience = 1000,\n",
    "   #                           lr_factor = 0.5,\n",
    "   #                           lr_patience = 10,\n",
    "   #                           lr_epsilon = 0.000001,\n",
    "   #                           lr_cooldown = 2,\n",
    "   #                           lr_minimum = 0.0000001,\n",
    "   #                           outputDir = folder)\n",
    "\n",
    "   # my_callbacks = [tf.keras.callbacks.EarlyStopping(patience=2),\n",
    "   #                 tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),\n",
    "   #                 tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "   #                ]\n",
    "\n",
    "    \n",
    "    training_history= model.fit(train_data,\n",
    "                                batch_size=batch_size,\n",
    "                                epochs=nepochs,\n",
    "                                verbose=VERBOSE,\n",
    "                                validation_data=val_data,\n",
    "                                class_weight=class_weight)\n",
    "\n",
    "                               \n",
    "    score = model.evaluate(val_data, verbose=VERBOSE) \n",
    "    print(\"Test score:\", score[0]) \n",
    "    print(\"Test accuracy:\", score[1]) \n",
    "    \n",
    "else:\n",
    "    from tensorflow.keras.models import load_model\n",
    "    model = load_model('weights.h5')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training_history.history.keys())\n",
    "import datetime\n",
    "word_time='_'+str(nepochs)+'ep_'+datetime.datetime.now().strftime(\"%H.%M.%S.%d%m%Y\")\n",
    "word_time=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot history: Loss\n",
    "plt.plot(training_history.history['loss'], label='training data')\n",
    "plt.plot(training_history.history['val_loss'], label='validation data')\n",
    "plt.title('model loss')     \n",
    "plt.ylabel('loss')     \n",
    "plt.xlabel('epoch')    \n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.savefig('plot_loss'+word_time+'.png', bbox_inches='tight', dpi=200) \n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot history: Accuracy\n",
    "plt.plot(training_history.history['accuracy'], label='training data)')\n",
    "plt.plot(training_history.history['val_accuracy'], label='validation data')\n",
    "plt.title('model accuracy')     \n",
    "plt.ylabel('accuracy')     \n",
    "plt.xlabel('epoch')  \n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "plt.savefig('plot_accuracy'+word_time+'.png', bbox_inches='tight', dpi=200) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save JSON and H5    \n",
    "json=\"model\"+word_time+\".json\"     \n",
    "h5=\"weights\"+word_time+\".h5\" \n",
    "model_json = model.to_json()     \n",
    "with open(json, \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    model.save_weights(h5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check performance\n",
    "We completed the training. Now its time to evaluate the performance and proceed with next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC curve (hls4ml code)\n",
    "Receiver Operating Characteristics\n",
    "AUC Area Under Curve\n",
    "Is a performance measurement for the classification problem at various threshold settings.\n",
    "ROC is a probability curve\n",
    "AUC represent the degree or measure of separability\n",
    "It tells how much the model is capable of distinguishing between classes\n",
    "The ROC curve is plotted with TPR against the FPR where\n",
    "True Positive Rate or sensitivity is  Total Positive / (Total Positive + False Negative)\n",
    "Specificity is Total Negative / (Total Negative + False Positives)\n",
    "False Positive Rate = 1 - Spevificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_keras = model.predict(X_valid)\n",
    "print(\"Accuracy: {}\".format(accuracy_score(np.argmax(y_valid, axis=1), np.argmax(y_keras, axis=1))))\n",
    "plt.figure(figsize=(9,9))\n",
    "_ = plotting.makeRoc(y_valid, y_keras, labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert the model\n",
    "Now we will go through the steps to convert the model we trained to a low-latency optimized FPGA firmware with hls4ml.\n",
    "First, we will evaluate its classification performance to make sure we haven't lost accuracy using the fixed-point data types.\n",
    "Then we will synthesize the model with Vivado HLS and check the metrics of latency and FPGA resource usage.\n",
    "## Make an hls4ml config & model\n",
    "\n",
    "The hls4ml Neural Network inference library is controlled through a configuration dictionary. In this example we'll use the most simple variation, later exercises will look at more advanced configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hls4ml\n",
    "#config = hls4ml.utils.config_from_keras_model(model, granularity='model') # same fxp across the model\n",
    "config = hls4ml.utils.config_from_keras_model(model, granularity='name') # custom layer datatype\n",
    "\n",
    "\n",
    "\n",
    "# numerical precision (do affect C-simulation)\n",
    "config['LayerName']['fc1'   ]['Precision']['weight'] = 'ap_fixed<32,16>'\n",
    "config['LayerName']['fc1'   ]['Precision']['bias']   = 'ap_fixed<32,16>'\n",
    "config['LayerName']['fc2'   ]['Precision']['weight'] = 'ap_fixed<32,16>'\n",
    "config['LayerName']['fc2'   ]['Precision']['bias']   = 'ap_fixed<32,16>'\n",
    "config['LayerName']['output']['Precision']['weight'] = 'ap_fixed<32,16>'\n",
    "config['LayerName']['output']['Precision']['bias']   = 'ap_fixed<32,16>'\n",
    "\n",
    "# implementation parameter (do NOT affect C-simulation)\n",
    "config['Model']['ReuseFactor'] = 4\n",
    "\n",
    "# Trace\n",
    "for layer in config['LayerName'].keys():\n",
    "    config['LayerName'][layer]['Trace'] = True\n",
    "\n",
    "\n",
    "\n",
    "print(\"-----------------------------------\")\n",
    "plotting.print_dict(config)\n",
    "print(\"-----------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profiling\n",
    "As you can see, we can choose the precision of everything in our Neural Network.\n",
    "This is a powerful way to tune the performance, but it's also complicated.\n",
    "The tools in hls4ml.model.profiling can help you choose the right precision for your model.\n",
    "(That said, training your model with quantization built in can get around this problem, and that is introduced in Part 4. So, don't go too far down the rabbit hole of tuning your data types without first trying out quantization aware training with QKeras.)\n",
    "\n",
    "The first thing to try is to numerically profile your model.\n",
    "This method plots the distribution of the weights (and biases) as a box and whisker plot.\n",
    "The grey boxes show the values which can be represented with the data types used in the hls_model.\n",
    "Generally, you need the box to overlap completely with the whisker 'to the right' (large values) otherwise you'll get saturation & wrap-around issues. \n",
    "It can be okay for the box not to overlap completely 'to the left' (small values), but finding how small you can go is a matter of trial-and-error.\n",
    "\n",
    "Providing data, in this case just using the first 1000 examples for speed, will show the same distributions captured at the output of each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hls_model = hls4ml.converters.convert_from_keras_model(model,\n",
    "                                                       hls_config=config,\n",
    "                                                       output_dir='model/hls4ml_prj',\n",
    "                                                       fpga_part='xcvu9p-flga2104-2L-e',\n",
    "                                                       project_name='hwFunc',\n",
    "                                                       clock_period=5,\n",
    "                                                       io_type='io_parallel')\n",
    "%matplotlib inline\n",
    "#hls4ml.model.profiling.numerical(model=model, hls_model=hls_model) # plot only weights\n",
    "hls4ml.model.profiling.numerical(model=model, hls_model=hls_model, X=X_valid[:1000]) # plot activation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customize\n",
    "Let's just try setting the precision of the first layer weights to something more narrow than 16 bits. Using fewer bits can save resources in the FPGA. After inspecting the profiling plot above, let's try 8 bits with 1 integer bit.\n",
    "\n",
    "Then create a new HLSModel, and display the profiling with the new config. This time, just display the weight profile by not providing any data 'X'. Then create the HLSModel and display the architecture. Notice the box around the weights of the first layer reflects the different precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualise what we created. The model architecture is shown, annotated with the shape and data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hls4ml.utils.plot_model(hls_model, show_shapes=True, show_precision=True, to_file=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trace\n",
    "When we start using customised precision throughout the model, it can be useful to collect the output from each layer to find out when things have gone wrong. \n",
    "We enable this trace collection by setting Trace = True for each layer whose output we want to collect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile, predict (from tutorial Part1)\n",
    "Now we need to check that this model performance is still good. We compile the hls_model, and then use `hls_model.predict` to execute the FPGA firmware with bit-accurate emulation on the CPU.\n",
    "\n",
    "\n",
    "\n",
    "## Compile, trace, predict (from tutorial Part2)\n",
    "\n",
    "Now we need to check that this model performance is still good after reducing the precision. We compile the hls_model, and now use the hls_model.trace method to collect the model output, and also the output for all the layers we enabled tracing for. This returns a dictionary with keys corresponding to the layer names of the model. Stored at that key is the array of values output by that layer, sampled from the provided data. A helper function get_ymodel_keras will return the same dictionary for the Keras model.\n",
    "\n",
    "We'll just run the trace for the first 1000 examples, since it takes a bit longer and uses more memory than just running predict.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hls_model.compile()\n",
    "\n",
    "X_valid = np.ascontiguousarray(X_valid) # required!\n",
    "hls4ml_pred, hls4ml_trace = hls_model.trace(X_valid[:1000])\n",
    "keras_trace = hls4ml.model.profiling.get_ymodel_keras(model, X_valid[:1000])\n",
    "\n",
    "\n",
    "y_hls = hls_model.predict(X_valid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect\n",
    "Now we can print out, make plots, or do any other more detailed analysis on the output of each layer to make sure we haven't made the performance worse. And if we have, we can quickly find out where. Let's just print the output of the first layer, for the first sample, for both the Keras and hls4ml models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layername ='output'\n",
    "evtID     = 35;\n",
    "\n",
    "print('Keras layer '+ layername + ' event %d' % evtID)\n",
    "print(keras_trace[layername][evtID])\n",
    "\n",
    "print('hls4ml layer '+ layername + ' event %d' % evtID)\n",
    "print(hls4ml_trace[layername][evtID])\n",
    "\n",
    "print(\"difference:\")\n",
    "print(keras_trace[layername][evtID]-hls4ml_trace[layername][evtID])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare\n",
    "That was easy! Now let's see how the performance compares to Keras:\n",
    "et's see if we lost performance by using 8 bits for the weights of the first layer by inspecting the accuracy and ROC curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Keras  Accuracy: {}\".format(accuracy_score(np.argmax(y_valid, axis=1), np.argmax(y_keras, axis=1))))\n",
    "print(\"hls4ml Accuracy: {}\".format(accuracy_score(np.argmax(y_valid, axis=1), np.argmax(y_hls, axis=1))))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 9))\n",
    "_ = plotting.makeRoc(y_valid, y_keras, labels)\n",
    "plt.gca().set_prop_cycle(None) # reset the colors\n",
    "_ = plotting.makeRoc(y_valid, y_hls, labels, linestyle='--')\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "lines = [Line2D([0], [0], ls='-'),\n",
    "         Line2D([0], [0], ls='--')]\n",
    "from matplotlib.legend import Legend\n",
    "leg = Legend(ax, lines, labels=['keras', 'hls4ml'],\n",
    "            loc='lower right', frameon=False)\n",
    "ax.add_artist(leg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthesize\n",
    "Now we'll actually use Vivado HLS to synthesize the model. We can run the build using a method of our `hls_model` object.\n",
    "After running this step, we can integrate the generated IP into a workflow to compile for a specific FPGA board.\n",
    "In this case, we'll just review the reports that Vivado HLS generates, checking the latency and resource usage.\n",
    "\n",
    "**This can take several minutes.**\n",
    "\n",
    "While the C-Synthesis is running, we can monitor the progress looking at the log file by opening a terminal from the notebook home, and executing:\n",
    "\n",
    "`tail -f model_1/hls4ml_prj/vivado_hls.log`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hls_model.build(csim=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the reports\n",
    "Print out the reports generated by Vivado HLS. Pay attention to the Latency and the 'Utilization Estimates' sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hls4ml.report.read_vivado_report('model_1/hls4ml_prj/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
